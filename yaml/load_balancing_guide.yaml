# Ray í´ëŸ¬ìŠ¤í„° ë¡œë“œ ë°¸ëŸ°ì‹± ìµœì í™” ê°€ì´ë“œ
# ê° ì»´í¬ë„ŒíŠ¸ë³„ ìµœì  ì„¤ì • ë° ì„±ëŠ¥ íŠœë‹

---
# 1. Ray Serve Service - ë¡œë“œ ë¶„ì‚° ìµœì í™”
apiVersion: v1
kind: Service
metadata:
  name: ray-deepseek-serve-optimized
  namespace: p-ncai-wbl
  labels:
    app: ray-deepseek-serve
    ray-cluster: ray-ku-junyoung
    component: ray-serve
    optimization: load-balanced
  annotations:
    # ë¡œë“œ ë°¸ëŸ°ì‹± ìµœì í™” ì–´ë…¸í…Œì´ì…˜
    service.kubernetes.io/topology-aware-hints: "auto"
    service.kubernetes.io/load-balancer-source-ranges: "0.0.0.0/0"
spec:
  type: ClusterIP
  ipFamilyPolicy: SingleStack
  ipFamilies: [ IPv4 ]
  selector:
    app: ray-deepseek-serve
    ray-cluster: ray-ku-junyoung
  # ðŸŽ¯ í•µì‹¬: sessionAffinity ë¹„í™œì„±í™”ë¡œ ì™„ì „í•œ ë¡œë“œ ë¶„ì‚°
  sessionAffinity: None
  # internalTrafficPolicy ì œê±° - í´ëŸ¬ìŠ¤í„° ì „ì²´ ë¶„ì‚°
  ports:
  - name: http
    port: 8000
    targetPort: 8000
    appProtocol: http
  - name: metrics
    port: 8080
    targetPort: 8080
    appProtocol: http

---
# 2. Ray Head Service - ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ìµœì í™”
apiVersion: v1
kind: Service
metadata:
  name: ray-ku-junyoung-head-optimized
  namespace: p-ncai-wbl
  labels:
    app: ray-ku-junyoung-head
    ray-cluster: ray-ku-junyoung
    component: ray-head
spec:
  # Headless ì„œë¹„ìŠ¤ - ì§ì ‘ Pod IP ë°˜í™˜
  clusterIP: None
  publishNotReadyAddresses: true
  ipFamilyPolicy: SingleStack
  ipFamilies: [ IPv4 ]
  selector:
    app: ray-ku-junyoung-head
    ray-cluster: ray-ku-junyoung
  ports:
  - name: gcs
    port: 6379
    targetPort: 6379
  - name: dashboard
    port: 8265
    targetPort: 8265
  - name: client
    port: 10001
    targetPort: 10001

---
# 3. ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•œ í…ŒìŠ¤íŠ¸ Service (sessionAffinity í™œì„±í™”)
apiVersion: v1
kind: Service
metadata:
  name: ray-deepseek-serve-sticky
  namespace: p-ncai-wbl
  labels:
    app: ray-deepseek-serve
    ray-cluster: ray-ku-junyoung
    component: ray-serve
    optimization: session-sticky
spec:
  type: ClusterIP
  selector:
    app: ray-deepseek-serve
    ray-cluster: ray-ku-junyoung
  # ë¹„êµìš©: sessionAffinity í™œì„±í™”
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600
  ports:
  - name: http
    port: 8000
    targetPort: 8000

---
# 4. ë¡œë“œ ë°¸ëŸ°ì‹± í…ŒìŠ¤íŠ¸ìš© ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: load-balancing-test
  namespace: p-ncai-wbl
  labels:
    component: testing
data:
  test_load_distribution.py: |
    #!/usr/bin/env python3
    """
    ë¡œë“œ ë°¸ëŸ°ì‹± ë¶„ì‚° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
    ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ì„¤ì •ì˜ ë¡œë“œ ë¶„ì‚° íš¨ê³¼ë¥¼ ë¹„êµ
    """
    import asyncio
    import aiohttp
    import time
    import json
    from collections import defaultdict
    from typing import Dict, List
    
    class LoadBalancingTester:
        def __init__(self):
            self.response_sources = defaultdict(int)
            self.response_times = []
            
        async def test_service(self, service_url: str, num_requests: int = 100):
            """íŠ¹ì • ì„œë¹„ìŠ¤ì˜ ë¡œë“œ ë¶„ì‚° í…ŒìŠ¤íŠ¸"""
            print(f"Testing load balancing for: {service_url}")
            
            async with aiohttp.ClientSession() as session:
                tasks = []
                for i in range(num_requests):
                    tasks.append(self.make_request(session, service_url, i))
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
            self.analyze_results(results)
        
        async def make_request(self, session: aiohttp.ClientSession, url: str, request_id: int):
            """ë‹¨ì¼ ìš”ì²­ ì‹¤í–‰"""
            start_time = time.time()
            try:
                async with session.get(f"{url}/v1/models", timeout=10) as response:
                    response_time = time.time() - start_time
                    self.response_times.append(response_time)
                    
                    # ì‘ë‹µ í—¤ë”ì—ì„œ ì„œë²„ ì •ë³´ ì¶”ì¶œ (ê°€ëŠ¥í•œ ê²½ìš°)
                    server_info = response.headers.get('Server', 'unknown')
                    pod_name = response.headers.get('X-Pod-Name', f'pod-{hash(str(response)) % 10}')
                    
                    self.response_sources[pod_name] += 1
                    
                    return {
                        'request_id': request_id,
                        'status': response.status,
                        'response_time': response_time,
                        'server': server_info,
                        'pod': pod_name
                    }
            except Exception as e:
                return {
                    'request_id': request_id,
                    'error': str(e),
                    'response_time': time.time() - start_time
                }
        
        def analyze_results(self, results: List):
            """ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥"""
            successful_requests = [r for r in results if isinstance(r, dict) and 'status' in r]
            failed_requests = [r for r in results if isinstance(r, dict) and 'error' in r]
            
            print(f"\n=== Load Balancing Analysis ===")
            print(f"Total requests: {len(results)}")
            print(f"Successful: {len(successful_requests)}")
            print(f"Failed: {len(failed_requests)}")
            
            if self.response_sources:
                print(f"\n=== Load Distribution ===")
                total_responses = sum(self.response_sources.values())
                for pod, count in sorted(self.response_sources.items()):
                    percentage = (count / total_responses) * 100
                    print(f"{pod}: {count} requests ({percentage:.1f}%)")
                
                # ë¶„ì‚° ê· ë“±ì„± ê³„ì‚°
                expected_per_pod = total_responses / len(self.response_sources)
                variance = sum((count - expected_per_pod) ** 2 for count in self.response_sources.values()) / len(self.response_sources)
                print(f"\nLoad distribution variance: {variance:.2f}")
                print(f"Lower variance = better load balancing")
            
            if self.response_times:
                avg_time = sum(self.response_times) / len(self.response_times)
                print(f"\nAverage response time: {avg_time*1000:.1f}ms")
    
    async def compare_services():
        """ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ì„¤ì • ë¹„êµ"""
        services = {
            "Optimized (No sessionAffinity)": "http://ray-deepseek-serve-optimized.p-ncai-wbl.svc.cluster.local:8000",
            "Sticky (sessionAffinity: ClientIP)": "http://ray-deepseek-serve-sticky.p-ncai-wbl.svc.cluster.local:8000",
            "Default": "http://ray-deepseek-serve.p-ncai-wbl.svc.cluster.local:8000"
        }
        
        for name, url in services.items():
            print(f"\n{'='*50}")
            print(f"Testing: {name}")
            print(f"{'='*50}")
            
            tester = LoadBalancingTester()
            try:
                await tester.test_service(url, num_requests=50)
            except Exception as e:
                print(f"Error testing {name}: {e}")
            
            # í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²©
            await asyncio.sleep(2)
    
    if __name__ == "__main__":
        asyncio.run(compare_services())
  
  benchmark_concurrent_load.py: |
    #!/usr/bin/env python3
    """
    ë™ì‹œ ìš”ì²­ ë¶€í•˜ í…ŒìŠ¤íŠ¸
    sessionAffinity ì„¤ì •ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´ ì¸¡ì •
    """
    import asyncio
    import aiohttp
    import time
    import statistics
    from typing import List, Dict
    
    async def concurrent_load_test(service_url: str, concurrent_requests: int, total_requests: int):
        """ë™ì‹œ ìš”ì²­ ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
        print(f"Load testing: {service_url}")
        print(f"Concurrent: {concurrent_requests}, Total: {total_requests}")
        
        semaphore = asyncio.Semaphore(concurrent_requests)
        response_times = []
        errors = []
        
        async def make_request(session: aiohttp.ClientSession, request_id: int):
            async with semaphore:
                start_time = time.time()
                try:
                    async with session.get(f"{service_url}/v1/models", timeout=30) as response:
                        await response.text()
                        response_time = time.time() - start_time
                        response_times.append(response_time)
                        return response.status
                except Exception as e:
                    errors.append(str(e))
                    return None
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        start_time = time.time()
        async with aiohttp.ClientSession() as session:
            tasks = [make_request(session, i) for i in range(total_requests)]
            results = await asyncio.gather(*tasks)
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        successful = len([r for r in results if r is not None])
        failed = len(errors)
        
        if response_times:
            p50 = statistics.median(response_times) * 1000
            p95 = statistics.quantiles(response_times, n=20)[18] * 1000 if len(response_times) > 20 else p50
            avg_time = statistics.mean(response_times) * 1000
        else:
            p50 = p95 = avg_time = 0
        
        throughput = successful / total_time
        error_rate = (failed / total_requests) * 100
        
        print(f"\n=== Results ===")
        print(f"Total time: {total_time:.1f}s")
        print(f"Successful requests: {successful}")
        print(f"Failed requests: {failed}")
        print(f"Error rate: {error_rate:.1f}%")
        print(f"Throughput: {throughput:.1f} req/s")
        print(f"Response times - P50: {p50:.1f}ms, P95: {p95:.1f}ms, Avg: {avg_time:.1f}ms")
        
        return {
            'throughput': throughput,
            'error_rate': error_rate,
            'p50': p50,
            'p95': p95,
            'successful': successful,
            'failed': failed
        }
    
    async def compare_load_balancing():
        """ë¡œë“œ ë°¸ëŸ°ì‹± ì„¤ì •ë³„ ì„±ëŠ¥ ë¹„êµ"""
        test_configs = [
            ("Optimized", "http://ray-deepseek-serve-optimized.p-ncai-wbl.svc.cluster.local:8000"),
            ("Sticky", "http://ray-deepseek-serve-sticky.p-ncai-wbl.svc.cluster.local:8000"),
        ]
        
        concurrent_levels = [10, 20, 40, 60]
        
        for config_name, service_url in test_configs:
            print(f"\n{'='*60}")
            print(f"Testing Configuration: {config_name}")
            print(f"{'='*60}")
            
            for concurrent in concurrent_levels:
                print(f"\n--- Concurrent Level: {concurrent} ---")
                try:
                    await concurrent_load_test(service_url, concurrent, concurrent * 5)
                    await asyncio.sleep(5)  # í…ŒìŠ¤íŠ¸ ê°„ íœ´ì‹
                except Exception as e:
                    print(f"Error: {e}")
    
    if __name__ == "__main__":
        asyncio.run(compare_load_balancing())
  
  apply_optimized_config.sh: |
    #!/bin/bash
    # ìµœì í™”ëœ ë¡œë“œ ë°¸ëŸ°ì‹± ì„¤ì • ì ìš© ìŠ¤í¬ë¦½íŠ¸
    
    NAMESPACE="p-ncai-wbl"
    
    echo "=== Applying Optimized Load Balancing Configuration ==="
    
    # 1. ê¸°ì¡´ ì„œë¹„ìŠ¤ ë°±ì—…
    echo "Backing up existing services..."
    kubectl get service ray-deepseek-serve -n $NAMESPACE -o yaml > /tmp/ray-deepseek-serve-backup.yaml
    kubectl get service ray-ku-junyoung-serve -n $NAMESPACE -o yaml > /tmp/ray-ku-junyoung-serve-backup.yaml 2>/dev/null || true
    
    # 2. ìµœì í™”ëœ ì„¤ì • ì ìš©
    echo "Applying optimized load balancing services..."
    kubectl apply -f /config/load_balancing_guide.yaml
    
    # 3. ê¸°ì¡´ ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
    echo "Updating existing services..."
    
    # ray-deepseek-serve ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
    kubectl patch service ray-deepseek-serve -n $NAMESPACE -p '{
      "spec": {
        "sessionAffinity": "None"
      }
    }'
    
    # sessionAffinityConfig ì œê±°
    kubectl patch service ray-deepseek-serve -n $NAMESPACE --type='merge' -p '{
      "spec": {
        "sessionAffinityConfig": null
      }
    }'
    
    # ray-ku-junyoung-serve ì„œë¹„ìŠ¤ë„ ë™ì¼í•˜ê²Œ ì—…ë°ì´íŠ¸ (ì¡´ìž¬í•˜ëŠ” ê²½ìš°)
    if kubectl get service ray-ku-junyoung-serve -n $NAMESPACE >/dev/null 2>&1; then
        kubectl patch service ray-ku-junyoung-serve -n $NAMESPACE -p '{
          "spec": {
            "sessionAffinity": "None"
          }
        }'
        kubectl patch service ray-ku-junyoung-serve -n $NAMESPACE --type='merge' -p '{
          "spec": {
            "sessionAffinityConfig": null
          }
        }'
    fi
    
    echo "=== Configuration Applied Successfully ==="
    echo
    echo "To test the load balancing:"
    echo "kubectl exec -n $NAMESPACE deployment/generate-response-monitor -- python /config/test_load_distribution.py"
    echo
    echo "To run performance comparison:"
    echo "kubectl exec -n $NAMESPACE deployment/generate-response-monitor -- python /config/benchmark_concurrent_load.py"
    echo
    echo "To rollback if needed:"
    echo "kubectl apply -f /tmp/ray-deepseek-serve-backup.yaml"
