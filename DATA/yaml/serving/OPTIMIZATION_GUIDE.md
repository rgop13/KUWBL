# ğŸš€ DeepSeek V3.1 ìµœì í™” ê°€ì´ë“œ (TP=16, PP=2)

## ğŸ“Š ìµœì  ì„¤ì • ë¶„ì„

### ğŸ¯ **ê¶Œì¥ êµ¬ì„±**
```yaml
TENSOR_PARALLEL_SIZE: 16    # 16 GPU per replica
PIPELINE_PARALLEL_SIZE: 2   # 2-stage pipeline  
NUM_REPLICAS: 3             # ìµœì  replica ìˆ˜
Total GPU: 96 (16 Ã— 2 Ã— 3)
```

### ğŸ”„ **ì„±ëŠ¥ vs ë¦¬ì†ŒìŠ¤ íŠ¸ë ˆì´ë“œì˜¤í”„**

#### **Option 1: TP=16, PP=2, Replicas=3 (ê¶Œì¥)**
- âœ… **GPU**: 96ê°œ ì‚¬ìš©
- âœ… **ì²˜ë¦¬ëŸ‰**: ë†’ìŒ (3ê°œ ë…ë¦½ replica)
- âœ… **ì•ˆì •ì„±**: ìµœê³  (ì¥ì•  ê²©ë¦¬)
- âœ… **ì§€ì—°ì‹œê°„**: ë‚®ìŒ (PP=2)
- âŒ **ë©”ëª¨ë¦¬**: ëª¨ë¸ 3ë°° ì¤‘ë³µ

#### **Option 2: TP=32, PP=1, Replicas=3**
- âœ… **GPU**: 96ê°œ ì‚¬ìš©
- âœ… **ì§€ì—°ì‹œê°„**: ìµœì € (PP=1)
- âŒ **í†µì‹ **: TP=32ë¡œ í†µì‹  ì˜¤ë²„í—¤ë“œ ì¦ê°€
- âŒ **ì•ˆì •ì„±**: 32 GPU ì¤‘ í•˜ë‚˜ ì‹¤íŒ¨ì‹œ ì „ì²´ ì˜í–¥

#### **Option 3: TP=16, PP=2, Replicas=6**
- âœ… **ì²˜ë¦¬ëŸ‰**: ìµœê³ 
- âŒ **GPU**: 192ê°œ í•„ìš”
- âŒ **ë¦¬ì†ŒìŠ¤**: ê³¼ë„í•œ GPU ì‚¬ìš©

## ğŸ›¡ï¸ ì•ˆì •ì„± ê°œì„ ì‚¬í•­

### **1. Pod ìƒëª…ì£¼ê¸° ìµœì í™”**
```yaml
# ë¬´ê±°ìš´ ëª¨ë¸ ê³ ë ¤í•œ ì—¬ìœ ìˆëŠ” ì„¤ì •
startupProbe:
  failureThreshold: 120    # 60ë¶„ í—ˆìš©
  periodSeconds: 30
  
livenessProbe:
  initialDelaySeconds: 600 # 10ë¶„ í›„ ì‹œì‘
  failureThreshold: 5      # 5ë¶„ ì—¬ìœ 
  
readinessProbe:
  initialDelaySeconds: 180 # 3ë¶„ ì´ˆê¸°í™”
  successThreshold: 2      # ì•ˆì •ì„± í™•ì¸
```

### **2. ë¦¬ì†ŒìŠ¤ ì—¬ìœ  í™•ë³´**
```yaml
resources:
  limits:
    cpu: "16"
    memory: "128Gi"        # ê¸°ì¡´ 64Gi â†’ 128Gi
    ephemeral-storage: "50Gi"
  requests:
    cpu: "12"              # ìµœì†Œ ë³´ì¥
    memory: "96Gi"         # ìµœì†Œ ë³´ì¥
```

### **3. í†µì‹  ì•ˆì •ì„± ê°•í™”**
```yaml
# NCCL ìµœì í™” (TP=16 ê³ ë ¤)
NCCL_SOCKET_NTHREADS: "4"
NCCL_NSOCKS_PERTHREAD: "2"
NCCL_BUFFSIZE: "8388608"     # 8MB ë²„í¼
NCCL_CROSS_NIC: "1"          # ë‹¤ì¤‘ NIC í™œìš©

# Ray ì•ˆì •ì„±
RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE: "1"
RAY_ENABLE_RECORD_TASK_EVENTS: "1"
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### **Replica ìˆ˜ ê²°ì • ê°€ì´ë“œ**
```bash
# GPU ê°€ìš©ì„± í™•ì¸
kubectl get nodes -o custom-columns="NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"

# ê¶Œì¥ ê³µì‹
Available_GPUs = Total_GPUs Ã— 0.8  # 20% ì—¬ìœ 
Optimal_Replicas = Available_GPUs Ã· (TP Ã— PP)
Max_Replicas = Available_GPUs Ã· (TP Ã— PP)

# ì˜ˆì‹œ: 160 GPU í™˜ê²½
Optimal_Replicas = 128 Ã· 32 = 4
Max_Replicas = 160 Ã· 32 = 5
```

### **ì²˜ë¦¬ëŸ‰ vs ì§€ì—°ì‹œê°„ ìµœì í™”**
```yaml
# ì²˜ë¦¬ëŸ‰ ìš°ì„  (ë°°ì¹˜ ì²˜ë¦¬)
MAX_NUM_SEQS: 128
GPU_MEMORY_UTILIZATION: 0.95

# ì§€ì—°ì‹œê°„ ìš°ì„  (ì‹¤ì‹œê°„ ì„œë¹™)
MAX_NUM_SEQS: 32
GPU_MEMORY_UTILIZATION: 0.85
```

## ğŸ”§ ìš´ì˜ ê°€ì´ë“œ

### **initContainer ì œê±° (ì¤‘ìš”!)**
```yaml
# âŒ ë¬¸ì œ: initContainerì—ì„œ IB ì²´í¬ ì‹¤íŒ¨
initContainers:
- name: check-ib
  # BackOff ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥

# âœ… í•´ê²°: main containerì—ì„œ ì²´í¬
containers:
- name: main
  command: ["/bin/bash", "-lc"]
  args:
  - |
    # IB ì²´í¬ í›„ TCP fallback ì„¤ì •
    if [ ! -d /sys/class/infiniband ]; then
      export NCCL_IB_DISABLE=1
    fi
    # ì •ìƒ ì‹œì‘
```

### **ë°°í¬ ìˆœì„œ**
1. **Head ë°°í¬**: `kubectl apply -f head_statefulset.yaml`
2. **Worker ë°°í¬**: `kubectl apply -f worker_deployment.yaml`
3. **GPU í™•ì¸**: ìµœì†Œ 96 GPU ê°€ìš©ì„± ì²´í¬
4. **Serve ë°°í¬**: `kubectl apply -f serve_deepseek.yaml`

### **ìƒíƒœ ëª¨ë‹ˆí„°ë§**
```bash
# GPU ì‚¬ìš©ëŸ‰ í™•ì¸
kubectl exec -it ray-ku-junyoung-head-0 -n p-ncai-wbl -- ray status

# Serve ìƒíƒœ í™•ì¸
kubectl exec -it deployment/ray-deepseek-serve -n p-ncai-wbl -- ray serve status

# Pod ì•ˆì •ì„± ëª¨ë‹ˆí„°ë§
kubectl get pods -n p-ncai-wbl -l ray-cluster=ray-ku-junyoung -w
```

### **ë¬¸ì œ í•´ê²°**
```bash
# OOM ë°œìƒì‹œ
# 1. GPU_MEMORY_UTILIZATION ê°ì†Œ (0.90 â†’ 0.85)
# 2. MAX_NUM_SEQS ê°ì†Œ (64 â†’ 32)
# 3. ë©”ëª¨ë¦¬ ë¦¬ì†ŒìŠ¤ ì¦ê°€

# í†µì‹  ì˜¤ë¥˜ì‹œ
# 1. IB/RDMA ìƒíƒœ í™•ì¸
# 2. NCCL ë””ë²„ê·¸ ë¡œê·¸ í™•ì¸
# 3. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± í…ŒìŠ¤íŠ¸

# ëŠë¦° ì‹œì‘ì‹œ
# 1. startupProbe failureThreshold ì¦ê°€
# 2. ëª¨ë¸ ìºì‹œ í™•ì¸
# 3. ë””ìŠ¤í¬ I/O ì„±ëŠ¥ í™•ì¸
```

## ğŸ¯ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### **ì˜ˆìƒ ì„±ëŠ¥ (TP=16, PP=2, Replicas=3)**
- **ì²˜ë¦¬ëŸ‰**: ~300 tokens/sec per replica
- **ì´ ì²˜ë¦¬ëŸ‰**: ~900 tokens/sec
- **ì§€ì—°ì‹œê°„**: ~2-3ì´ˆ (16K context)
- **ë™ì‹œ ìš”ì²­**: ~192ê°œ (64 Ã— 3)

### **ìŠ¤ì¼€ì¼ë§ ê°€ì´ë“œ**
```yaml
# ì²˜ë¦¬ëŸ‰ 2ë°° ì¦ê°€ í•„ìš”ì‹œ
NUM_REPLICAS: 6  # 192 GPU í•„ìš”

# ì§€ì—°ì‹œê°„ 50% ê°ì†Œ í•„ìš”ì‹œ
PIPELINE_PARALLEL_SIZE: 1  # TP=32, PP=1
TENSOR_PARALLEL_SIZE: 32
```

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] GPU ê°€ìš©ì„±: ìµœì†Œ 96ê°œ í™•ì¸
- [ ] ë©”ëª¨ë¦¬: ë…¸ë“œë‹¹ ìµœì†Œ 512GB
- [ ] ë„¤íŠ¸ì›Œí¬: IB/RDMA í™œì„±í™” í™•ì¸
- [ ] ìŠ¤í† ë¦¬ì§€: ëª¨ë¸ ìºì‹œìš© ê³ ì† ë””ìŠ¤í¬
- [ ] ëª¨ë‹ˆí„°ë§: Prometheus/Grafana ì„¤ì •
- [ ] ë°±ì—…: ëª¨ë¸ ê°€ì¤‘ì¹˜ ë°±ì—… ê³„íš
